{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Hyper Parameter Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import modules. This includes<br>numpy for computations<br>pandas for data handling<br>matplotlib for display<br>scikit learn for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.datasets.fetch_mldata imports datasets found in scikitlearn's database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the image and labels. The image comes unrolled into a 784 points (28x28 unrolled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data and labels\n",
    "\n",
    "Data = np.asarray(pd.read_csv('train.csv'))\n",
    "X_data, y_data = Data[:,1:], Data[:,0]\n",
    "X_test = np.asarray(pd.read_csv('test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data to have inputs between -1 and 1 helps improve the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale mnist data\n",
    "\n",
    "X_data_scaled = X_data/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split in 80% training data and 20% test data. The dataset is stratified during splitting so the training data is evenly distributed among the target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a loop to identify which combination of parameters returns the highest accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate MLPClassifier Model\n",
    "\n",
    "clf = MLPClassifier(solver = 'sgd', alpha = 1e-5, learning_rate = 'adaptive',\n",
    "                    hidden_layer_sizes=(400,), random_state = 42, tol = 1e-4,\n",
    "                    verbose = 100, max_iter=100, learning_rate_init = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38135026\n",
      "Iteration 2, loss = 0.18004798\n",
      "Iteration 3, loss = 0.13110927\n",
      "Iteration 4, loss = 0.10178155\n",
      "Iteration 5, loss = 0.08292971\n",
      "Iteration 6, loss = 0.06832672\n",
      "Iteration 7, loss = 0.05789178\n",
      "Iteration 8, loss = 0.04941535\n",
      "Iteration 9, loss = 0.04252621\n",
      "Iteration 10, loss = 0.03678323\n",
      "Iteration 11, loss = 0.03185751\n",
      "Iteration 12, loss = 0.02764557\n",
      "Iteration 13, loss = 0.02407163\n",
      "Iteration 14, loss = 0.02149272\n",
      "Iteration 15, loss = 0.01857352\n",
      "Iteration 16, loss = 0.01655236\n",
      "Iteration 17, loss = 0.01468884\n",
      "Iteration 18, loss = 0.01294943\n",
      "Iteration 19, loss = 0.01156816\n",
      "Iteration 20, loss = 0.01047853\n",
      "Iteration 21, loss = 0.00938549\n",
      "Iteration 22, loss = 0.00845598\n",
      "Iteration 23, loss = 0.00768071\n",
      "Iteration 24, loss = 0.00702983\n",
      "Iteration 25, loss = 0.00642934\n",
      "Iteration 26, loss = 0.00589973\n",
      "Iteration 27, loss = 0.00551407\n",
      "Iteration 28, loss = 0.00509831\n",
      "Iteration 29, loss = 0.00481753\n",
      "Iteration 30, loss = 0.00451151\n",
      "Iteration 31, loss = 0.00421853\n",
      "Iteration 32, loss = 0.00395588\n",
      "Iteration 33, loss = 0.00380128\n",
      "Iteration 34, loss = 0.00357807\n",
      "Iteration 35, loss = 0.00339033\n",
      "Iteration 36, loss = 0.00328472\n",
      "Iteration 37, loss = 0.00306123\n",
      "Iteration 38, loss = 0.00291854\n",
      "Iteration 39, loss = 0.00282204\n",
      "Iteration 40, loss = 0.00268984\n",
      "Iteration 41, loss = 0.00258932\n",
      "Iteration 42, loss = 0.00249623\n",
      "Iteration 43, loss = 0.00239727\n",
      "Iteration 44, loss = 0.00230120\n",
      "Iteration 45, loss = 0.00223003\n",
      "Iteration 46, loss = 0.00213971\n",
      "Iteration 47, loss = 0.00208234\n",
      "Iteration 48, loss = 0.00201652\n",
      "Iteration 49, loss = 0.00195341\n",
      "Iteration 50, loss = 0.00190318\n",
      "Iteration 51, loss = 0.00183511\n",
      "Iteration 52, loss = 0.00178456\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.010000\n",
      "Iteration 53, loss = 0.00166821\n",
      "Iteration 54, loss = 0.00165375\n",
      "Iteration 55, loss = 0.00164427\n",
      "Iteration 56, loss = 0.00163592\n",
      "Iteration 57, loss = 0.00162364\n",
      "Iteration 58, loss = 0.00161814\n",
      "Iteration 59, loss = 0.00160749\n",
      "Iteration 60, loss = 0.00160186\n",
      "Iteration 61, loss = 0.00159228\n",
      "Iteration 62, loss = 0.00158530\n",
      "Iteration 63, loss = 0.00157671\n",
      "Iteration 64, loss = 0.00156901\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.002000\n",
      "Iteration 65, loss = 0.00154974\n",
      "Iteration 66, loss = 0.00154681\n",
      "Iteration 67, loss = 0.00154495\n",
      "Iteration 68, loss = 0.00154366\n",
      "Iteration 69, loss = 0.00154197\n",
      "Iteration 70, loss = 0.00154041\n",
      "Iteration 71, loss = 0.00153882\n",
      "Iteration 72, loss = 0.00153736\n",
      "Iteration 73, loss = 0.00153606\n",
      "Iteration 74, loss = 0.00153413\n",
      "Iteration 75, loss = 0.00153300\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000400\n",
      "Iteration 76, loss = 0.00152859\n",
      "Iteration 77, loss = 0.00152825\n",
      "Iteration 78, loss = 0.00152786\n",
      "Iteration 79, loss = 0.00152759\n",
      "Iteration 80, loss = 0.00152730\n",
      "Iteration 81, loss = 0.00152702\n",
      "Iteration 82, loss = 0.00152673\n",
      "Iteration 83, loss = 0.00152645\n",
      "Iteration 84, loss = 0.00152615\n",
      "Iteration 85, loss = 0.00152581\n",
      "Iteration 86, loss = 0.00152554\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000080\n",
      "Iteration 87, loss = 0.00152464\n",
      "Iteration 88, loss = 0.00152458\n",
      "Iteration 89, loss = 0.00152452\n",
      "Iteration 90, loss = 0.00152446\n",
      "Iteration 91, loss = 0.00152441\n",
      "Iteration 92, loss = 0.00152433\n",
      "Iteration 93, loss = 0.00152427\n",
      "Iteration 94, loss = 0.00152422\n",
      "Iteration 95, loss = 0.00152417\n",
      "Iteration 96, loss = 0.00152410\n",
      "Iteration 97, loss = 0.00152404\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000016\n",
      "Iteration 98, loss = 0.00152387\n",
      "Iteration 99, loss = 0.00152386\n",
      "Iteration 100, loss = 0.00152385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\princ\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(400,), learning_rate='adaptive',\n",
       "       learning_rate_init=0.05, max_iter=100, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=100, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train model\n",
    "\n",
    "clf.fit(X_data_scaled,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict based on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 28000/28000 [00:04<00:00, 5888.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Predict \n",
    "y_pred=[]\n",
    "y_index=[]\n",
    "for i in tqdm(range(0,X_test.shape[0])):\n",
    "    y_pred.append(clf.predict(X_test[i,:].reshape(1,-1))[0])\n",
    "    y_index.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame({'ImageId':y_index,\n",
    "                      'Label':y_pred})\n",
    "final.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_data_scaled,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27970</th>\n",
       "      <td>27971</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27971</th>\n",
       "      <td>27972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27972</th>\n",
       "      <td>27973</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27973</th>\n",
       "      <td>27974</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27974</th>\n",
       "      <td>27975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27975</th>\n",
       "      <td>27976</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27976</th>\n",
       "      <td>27977</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977</th>\n",
       "      <td>27978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27978</th>\n",
       "      <td>27979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27979</th>\n",
       "      <td>27980</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27980</th>\n",
       "      <td>27981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27981</th>\n",
       "      <td>27982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27982</th>\n",
       "      <td>27983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27983</th>\n",
       "      <td>27984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27984</th>\n",
       "      <td>27985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27985</th>\n",
       "      <td>27986</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>27987</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27987</th>\n",
       "      <td>27988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27988</th>\n",
       "      <td>27989</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27989</th>\n",
       "      <td>27990</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27990</th>\n",
       "      <td>27991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>27992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>27993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>27994</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>27995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "5            6      7\n",
       "6            7      0\n",
       "7            8      3\n",
       "8            9      0\n",
       "9           10      3\n",
       "10          11      5\n",
       "11          12      7\n",
       "12          13      4\n",
       "13          14      0\n",
       "14          15      4\n",
       "15          16      3\n",
       "16          17      3\n",
       "17          18      1\n",
       "18          19      9\n",
       "19          20      0\n",
       "20          21      9\n",
       "21          22      1\n",
       "22          23      1\n",
       "23          24      5\n",
       "24          25      7\n",
       "25          26      4\n",
       "26          27      2\n",
       "27          28      7\n",
       "28          29      4\n",
       "29          30      7\n",
       "...        ...    ...\n",
       "27970    27971      5\n",
       "27971    27972      0\n",
       "27972    27973      4\n",
       "27973    27974      8\n",
       "27974    27975      0\n",
       "27975    27976      3\n",
       "27976    27977      6\n",
       "27977    27978      0\n",
       "27978    27979      1\n",
       "27979    27980      9\n",
       "27980    27981      3\n",
       "27981    27982      1\n",
       "27982    27983      1\n",
       "27983    27984      0\n",
       "27984    27985      4\n",
       "27985    27986      5\n",
       "27986    27987      2\n",
       "27987    27988      2\n",
       "27988    27989      9\n",
       "27989    27990      6\n",
       "27990    27991      7\n",
       "27991    27992      6\n",
       "27992    27993      1\n",
       "27993    27994      9\n",
       "27994    27995      7\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[1000,:].reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
